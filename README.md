# lemon_spiders
>Python 爬虫实践

这段时间在[公司]("http://www.speechocean.com")实习,工作主要是用爬虫收集各种语言的语料。实习快结束了，我在这里些写点文档介绍一下爬虫的实现方案，以及到的用各种开源工具。

既是对工作的总结，也希望能给后来的同学提供一些参考。水平有限，欢迎指正。 

##101
101 

* [requests]("http://cn.python-requests.org/zh_CN/latest/")

  
* [beautifulsoup]("https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/#id40")


* [python-bloomfilter]("https://github.com/jaybaird/python-bloomfilter")


* [threadpool]("http://chrisarndt.de/projects/threadpool/api/")



##框架scrapy 

scrapy
![image](http://)
![404]("https://github.com/aquairus/lemon_spiders/blob/master/doc/scrapy_architecture.png")

[中文文档]("http://scrapy-chs.readthedocs.org/zh_CN/latest/intro/tutorial.html")
##内容获取
   crwal rule
    ajax
    
##分布式
主从 完全分布式
    redis


[redis-py]("https://github.com/andymccurdy/redis-py")

[scrapy-redis]("https://github.com/rolando/scrapy-redis")


[mongodb]("https://github.com/mongodb/mongo-python-driver")
##性能

##维护
   fab
   supervisor